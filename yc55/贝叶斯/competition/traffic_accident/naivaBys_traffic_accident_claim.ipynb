{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CaseId\t案例编号，没有实际意义\n",
    "Q1\t理赔员现场勘察采集的信息，Q1代表第一个问题的信息。信息被编码成数字，数字的大小不代表真实的关系。\n",
    "Qk\t同上，Qk代表第k个问题的信息。一共36个问题。\n",
    "Evaluation\t表示最终审核结果。0表示授予理赔，1表示未通过理赔审核。在test.csv中，这是需要被预测的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmin_max_sclar=preprocessing.MinMaxScaler()\\nx_max_min=min_max_sclar.fit_transform(data_ques)\\n\\nx_train,x_test,y_train,y_test=train_test_split(x_max_min,data_target,test_size=0.25,random_state=0,stratify=data_target)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#离差标准化\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#切割数据\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "file=pd.read_csv('train.csv',iterator=True)   #  iterator=True后通过get_chunk选取任意行\n",
    "lines = file.get_chunk(10000)\n",
    "#print(lines.describe())\n",
    "\n",
    "data_target=lines['Evaluation']\n",
    "data_ques=lines.drop(['CaseId','Evaluation'],axis=1)\n",
    "\n",
    "'''\n",
    "min_max_sclar=preprocessing.MinMaxScaler()\n",
    "x_max_min=min_max_sclar.fit_transform(data_ques)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_max_min,data_target,test_size=0.25,random_state=0,stratify=data_target)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.277300</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>3.966300</td>\n",
       "      <td>1.16560</td>\n",
       "      <td>9.504600</td>\n",
       "      <td>0.98080</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.642200</td>\n",
       "      <td>0.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.164544</td>\n",
       "      <td>0.154161</td>\n",
       "      <td>0.216849</td>\n",
       "      <td>0.257341</td>\n",
       "      <td>0.316996</td>\n",
       "      <td>0.534703</td>\n",
       "      <td>0.602246</td>\n",
       "      <td>0.878682</td>\n",
       "      <td>0.262694</td>\n",
       "      <td>0.67945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02236</td>\n",
       "      <td>0.981168</td>\n",
       "      <td>3.682543</td>\n",
       "      <td>0.62323</td>\n",
       "      <td>8.950586</td>\n",
       "      <td>0.23966</td>\n",
       "      <td>0.382601</td>\n",
       "      <td>0.082783</td>\n",
       "      <td>0.479377</td>\n",
       "      <td>0.477182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q1            Q2            Q3            Q4            Q5  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.015100      0.011700      0.026100      0.038500      0.042700   \n",
       "std        0.164544      0.154161      0.216849      0.257341      0.316996   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        3.000000      3.000000      3.000000      3.000000      3.000000   \n",
       "\n",
       "                 Q6            Q7            Q8            Q9          Q10  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.00000   \n",
       "mean       0.089000      0.117200      0.277300      0.037400      0.18760   \n",
       "std        0.534703      0.602246      0.878682      0.262694      0.67945   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "max        6.000000      6.000000      8.000000      4.000000      5.00000   \n",
       "\n",
       "           ...               Q27           Q28           Q29          Q30  \\\n",
       "count      ...       10000.00000  10000.000000  10000.000000  10000.00000   \n",
       "mean       ...           0.00030      0.617500      3.966300      1.16560   \n",
       "std        ...           0.02236      0.981168      3.682543      0.62323   \n",
       "min        ...           0.00000      0.000000      0.000000      0.00000   \n",
       "25%        ...           0.00000      0.000000      2.000000      1.00000   \n",
       "50%        ...           0.00000      0.000000      3.000000      1.00000   \n",
       "75%        ...           0.00000      1.000000      5.000000      1.00000   \n",
       "max        ...           2.00000      4.000000     39.000000      3.00000   \n",
       "\n",
       "                Q31          Q32           Q33           Q34           Q35  \\\n",
       "count  10000.000000  10000.00000  10000.000000  10000.000000  10000.000000   \n",
       "mean       9.504600      0.98080      0.015200      0.006900      0.642200   \n",
       "std        8.950586      0.23966      0.382601      0.082783      0.479377   \n",
       "min        0.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      1.00000      0.000000      0.000000      0.000000   \n",
       "50%        6.000000      1.00000      0.000000      0.000000      1.000000   \n",
       "75%       14.000000      1.00000      0.000000      0.000000      1.000000   \n",
       "max       42.000000      3.00000     14.000000      1.000000      1.000000   \n",
       "\n",
       "                Q36  \n",
       "count  10000.000000  \n",
       "mean       0.649400  \n",
       "std        0.477182  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ques.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn import metrics\n",
    "#高斯模型\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "# 模型拟合\n",
    "gnb.fit(x_train, y_train)\n",
    "# 模型在测试数据集上的预测\n",
    "y_pred = gnb.predict(x_test)\n",
    "\n",
    "cm = pd.crosstab(y_pred,y_test)   #混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33905</td>\n",
       "      <td>2268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8195</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation      0     1\n",
       "row_0                  \n",
       "0           33905  2268\n",
       "1            8195  5632"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的准确率为：\n",
      " 0.79074\n",
      "模型的评估报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.81      0.87     42100\n",
      "          1       0.41      0.71      0.52      7900\n",
      "\n",
      "avg / total       0.85      0.79      0.81     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('模型的准确率为：\\n',metrics.accuracy_score(y_test, y_pred))\n",
    "print('模型的评估报告：\\n',metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42075</td>\n",
       "      <td>7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation      0     1\n",
       "row_0                  \n",
       "0           42075  7650\n",
       "1              25   250"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#换个模型  多项式\n",
    "\n",
    "mnb=naive_bayes.MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "y_predict=mnb.predict(x_test)\n",
    "print(y_predict.shape)\n",
    "cm= pd.crosstab(y_predict,y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的准确率为：\n",
      " 0.8465\n",
      "模型的评估报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92     42100\n",
      "          1       0.91      0.03      0.06      7900\n",
      "\n",
      "avg / total       0.86      0.85      0.78     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('模型的准确率为：\\n',metrics.accuracy_score(y_test, y_predict))\n",
    "print('模型的评估报告：\\n',metrics.classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36517</td>\n",
       "      <td>2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5583</td>\n",
       "      <td>5152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation      0     1\n",
       "row_0                  \n",
       "0           36517  2748\n",
       "1            5583  5152"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#换个模型  伯努利\n",
    "bum=naive_bayes.BernoulliNB()\n",
    "bum.fit(x_train,y_train)\n",
    "y_predict=bum.predict(x_test)\n",
    "\n",
    "cm=pd.crosstab(y_predict,y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的准确率为：\n",
      " 0.83338\n",
      "模型的评估报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.87      0.90     42100\n",
      "          1       0.48      0.65      0.55      7900\n",
      "\n",
      "avg / total       0.86      0.83      0.84     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('模型的准确率为：\\n',metrics.accuracy_score(y_test, y_predict))\n",
    "print('模型的评估报告：\\n',metrics.classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.72343496e+00   4.10017912e+01   8.47592902e+01   1.62237825e+01\n",
      "   8.84263902e+01   2.77585440e+01   1.33196779e-01   3.42798073e+01\n",
      "   4.17822473e+01   7.10368991e-01   3.48103268e-01   3.90872070e+00\n",
      "   9.90399985e+01   7.03871021e-02   4.10277732e+01   5.29865852e+00\n",
      "   1.12712180e+02   8.25383795e+00   3.97967681e+01   2.32639047e+01\n",
      "   1.61300463e+02   1.52421688e+01   7.24911782e-01   6.62301251e+00\n",
      "   1.42131016e+01   8.31443446e+00   2.22793257e+00   1.33718656e+04\n",
      "   5.62656754e-02   2.29237451e+03   5.24675656e-05   9.46222033e+00\n",
      "   1.07111675e+02   4.64034721e+03   3.54909545e+03   6.27969872e+03]\n",
      "(200000, 30)\n"
     ]
    }
   ],
   "source": [
    "#可以看出来 多项式  的效果最好 所以  选择多项式做为下面的主要测试方向\n",
    "\n",
    "#离差标准化\n",
    "from sklearn import preprocessing\n",
    "min_max_sclar=preprocessing.MinMaxScaler()\n",
    "x_max_min=min_max_sclar.fit_transform(data_ques)   \n",
    "\n",
    "\n",
    "'''\n",
    "特征选择\n",
    "'''\n",
    "from sklearn.feature_selection import SelectKBest,SelectPercentile  #移除top以外的数据\n",
    "from sklearn.feature_selection import chi2  #卡方效验\n",
    "\n",
    "skb=SelectKBest(chi2,30)\n",
    "new_data=skb.fit_transform(x_max_min,data_target)\n",
    "print(skb.scores_)\n",
    "print(new_data.shape)\n",
    "x_train,x_test,y_train,y_test=train_test_split(new_data,data_target,test_size=0.25,random_state=0,stratify=data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42075</td>\n",
       "      <td>7651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation      0     1\n",
       "row_0                  \n",
       "0           42075  7651\n",
       "1              25   249"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb=naive_bayes.MultinomialNB()\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "bul=naive_bayes.BernoulliNB()\n",
    "\n",
    "#多项式   （没改变）\n",
    "mnb.fit(x_train,y_train)\n",
    "y_predict=mnb.predict(x_test)\n",
    "\n",
    "cm= pd.crosstab(y_predict,y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的准确率为：\n",
      " 0.84648\n",
      "模型的评估报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92     42100\n",
      "          1       0.91      0.03      0.06      7900\n",
      "\n",
      "avg / total       0.86      0.85      0.78     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('模型的准确率为：\\n',metrics.accuracy_score(y_test, y_predict))\n",
    "print('模型的评估报告：\\n',metrics.classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36661</td>\n",
       "      <td>2944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5439</td>\n",
       "      <td>4956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation      0     1\n",
       "row_0                  \n",
       "0           36661  2944\n",
       "1            5439  4956"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  看看  伯努利\n",
    "bul.fit(x_train,y_train)\n",
    "y_predict=bul.predict(x_test)\n",
    "cm=pd.crosstab(y_predict,y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的准确率为：\n",
      " 0.83234\n",
      "模型的评估报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.87      0.90     42100\n",
      "          1       0.48      0.63      0.54      7900\n",
      "\n",
      "avg / total       0.85      0.83      0.84     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('模型的准确率为：\\n',metrics.accuracy_score(y_test, y_predict))\n",
    "print('模型的评估报告：\\n',metrics.classification_report(y_test, y_predict))  \n",
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmin_max_sclar=preprocessing.MinMaxScaler()\\nx_max_min=min_max_sclar.fit_transform(data_ques)\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  上面基本确定了  使用什么方法来实现  构建模型  \n",
    "\n",
    "#离差标准化\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#切割数据\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "file=pd.read_csv('train1.csv')\n",
    "data_target=file['Evaluation']\n",
    "data_ques=file.drop(['CaseId','Evaluation'],axis=1)\n",
    "\n",
    "min_max_sclar=preprocessing.MinMaxScaler()\n",
    "x_max_min=min_max_sclar.fit_transform(data_ques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 160811, 1: 30190}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total={}   #  0     1   的先验概率\n",
    "for item in data_target:\n",
    "    total.setdefault(item,0)\n",
    "    total[item]+=1\n",
    "    \n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 29887, 1: 225, 2: 45, 3: 33}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#judgement  里面有了所有的条件的次数   {1:{'q1':{0: 31284, 1: 236, 2: 46, 3: 35} } }\n",
    "judgement={}\n",
    "judgement.setdefault(0,{})\n",
    "judgement.setdefault(1,{})\n",
    "dataFarm='q1\\tq2\\tq3\\tq4\\tq5\\tq6\\tq7\\tq8\\tq9\\tq10\\tq11\\tq12\\tq13\\tq14\\tq15\\tq16\\tq17\\tq18\\tq19\\tq20\\tq21\\tq22\\tq23\\tq24\\tq25\\tq26\\tq27\\tq28\\tq29\\tq30\\tq31\\tq32\\tq33\\tq34\\tq35\\tq36'\n",
    "lines=dataFarm.strip().split('\\t')\n",
    "for i in range(len(data_target)):\n",
    "    judge=data_target.ix[i]\n",
    "    index=0\n",
    "    for x_value in data_ques.ix[i].values:\n",
    "        question=lines[index]\n",
    "        index+=1\n",
    "        judgement[judge].setdefault(question,{})\n",
    "        judgement[judge][question].setdefault(x_value,0)\n",
    "        judgement[judge][question][x_value]+=1\n",
    "        \n",
    "judgement[1]['q1']    #0: 31284, 1: 236, 2: 46, 3: 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lapulasi(lines,data,judgement,total,alpha=1):    #  拉普拉斯平滑  算出概率    (次数+1) /(所有的情况+total)\n",
    "    '''\n",
    "    题目要求  求出判断出 1 的概率 所以接下来的数据：\n",
    "    \n",
    "    lines [q1,q2,.....]\n",
    "    data  数据    {'q1':1,'q2':0,....}\n",
    "    judgement  你给的所有情况  \n",
    "    total 总的 0  1 的次数  \n",
    "    '''\n",
    "    may0=0.0\n",
    "    may1=0.0\n",
    "    for line in lines:\n",
    "        judgement[0][line].setdefault(data[line],0)\n",
    "        judgement[1][line].setdefault(data[line],0)\n",
    "        may0+=(judgement[0][line][ data[line] ]+alpha)/(total[0]+len(judgement[0][line] ) )   #0的概率下的可能性\n",
    "        may1+=(judgement[1][line][ data[line] ]+alpha)/(total[1]+len(judgement[1][line] ) )   #1的概率可能性\n",
    "    '''\n",
    "    may0=may0/len(lines)\n",
    "    may1=may1/len(lines)\n",
    "    '''\n",
    "    return (may1/(may0+may1) )  #取均值  由于不知道问题的是什么无法进行权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015234814863880242"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may=(judgement[1]['q1'][2]+1)/(total[1]+len(judgement[1]['q1'] ) )\n",
    "may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmin_max_sclar=preprocessing.MinMaxScaler()\\nx_max_min=min_max_sclar.fit_transform(data_test_ques)\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=pd.read_csv('test1.csv')\n",
    "data_test_target=file['Evaluation']\n",
    "data_test_ques=file.drop(['CaseId','Evaluation'],axis=1)\n",
    "\n",
    "'''\n",
    "min_max_sclar=preprocessing.MinMaxScaler()\n",
    "x_max_min=min_max_sclar.fit_transform(data_test_ques)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'q1': 0,\n",
       " 'q10': 0,\n",
       " 'q11': 1,\n",
       " 'q12': 0,\n",
       " 'q13': 0,\n",
       " 'q14': 0,\n",
       " 'q15': 0,\n",
       " 'q16': 0,\n",
       " 'q17': 0,\n",
       " 'q18': 0,\n",
       " 'q19': 0,\n",
       " 'q2': 0,\n",
       " 'q20': 0,\n",
       " 'q21': 0,\n",
       " 'q22': 0,\n",
       " 'q23': 0,\n",
       " 'q24': 0,\n",
       " 'q25': 0,\n",
       " 'q26': 0,\n",
       " 'q27': 0,\n",
       " 'q28': 0,\n",
       " 'q29': 2,\n",
       " 'q3': 0,\n",
       " 'q30': 1,\n",
       " 'q31': 14,\n",
       " 'q32': 1,\n",
       " 'q33': 0,\n",
       " 'q34': 0,\n",
       " 'q35': 0,\n",
       " 'q36': 0,\n",
       " 'q4': 1,\n",
       " 'q5': 0,\n",
       " 'q6': 0,\n",
       " 'q7': 0,\n",
       " 'q8': 0,\n",
       " 'q9': 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafa={}\n",
    "for i in range(len(data_test_ques) ):\n",
    "    count=0\n",
    "    datafa.setdefault(i,{})\n",
    "    for x_value in data_test_ques.ix[i].values:\n",
    "        datafa[i].setdefault(lines[count],0)\n",
    "        datafa[i][lines[count] ]= x_value\n",
    "        count+=1\n",
    "#print(len(datafa))\n",
    "#datafa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resu={}\n",
    "dataFarm='q1\\tq2\\tq3\\tq4\\tq5\\tq6\\tq7\\tq8\\tq9\\tq10\\tq11\\tq12\\tq13\\tq14\\tq15\\tq16\\tq17\\tq18\\tq19\\tq20\\tq21\\tq22\\tq23\\tq24\\tq25\\tq26\\tq27\\tq28\\tq29\\tq30\\tq31\\tq32\\tq33\\tq34\\tq35\\tq36'\n",
    "lines=dataFarm.strip().split('\\t')\n",
    "for i in range(len(datafa)):\n",
    "    test_data=datafa[i]\n",
    "    aws=lapulasi(lines,test_data,judgement,total)  #  lines,data,judgement,total\n",
    "    resu[i]=aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.48552655895772884,\n",
       " 1: 0.5021689856831644,\n",
       " 2: 0.4856130473093521,\n",
       " 3: 0.49788174906950683,\n",
       " 4: 0.502079083829727,\n",
       " 5: 0.4850278608287902,\n",
       " 6: 0.48603849788000436,\n",
       " 7: 0.5065828464368228,\n",
       " 8: 0.5020254981013332,\n",
       " 9: 0.48829147531312717,\n",
       " 10: 0.4891223354288243,\n",
       " 11: 0.4977127850036983,\n",
       " 12: 0.5061717146723468,\n",
       " 13: 0.5023645039953357,\n",
       " 14: 0.5022140135052201,\n",
       " 15: 0.5021819932303986,\n",
       " 16: 0.5048939304837601,\n",
       " 17: 0.5023578286504855,\n",
       " 18: 0.49807492774380363,\n",
       " 19: 0.4889910942045292,\n",
       " 20: 0.4853918624533338,\n",
       " 21: 0.48852469745763566,\n",
       " 22: 0.485736875759787,\n",
       " 23: 0.4855459175228407,\n",
       " 24: 0.5021689856831644,\n",
       " 25: 0.4850753619300866,\n",
       " 26: 0.49166808411895413,\n",
       " 27: 0.48548565389278336,\n",
       " 28: 0.4856130473093521,\n",
       " 29: 0.4976218339054155,\n",
       " 30: 0.508732620849627,\n",
       " 31: 0.5040793054009447,\n",
       " 32: 0.48550255468314496,\n",
       " 33: 0.4974519251744379,\n",
       " 34: 0.49829283182706136,\n",
       " 35: 0.4857582238768699,\n",
       " 36: 0.5163966749173609,\n",
       " 37: 0.5125762438690818,\n",
       " 38: 0.5021689856831644,\n",
       " 39: 0.502079083829727,\n",
       " 40: 0.5086494354521602,\n",
       " 41: 0.5070612271198505,\n",
       " 42: 0.5164979687850194,\n",
       " 43: 0.5099221346452083,\n",
       " 44: 0.5121167754008918,\n",
       " 45: 0.4854874292246123,\n",
       " 46: 0.4850174968491262,\n",
       " 47: 0.5065345493216631,\n",
       " 48: 0.5022408094230172,\n",
       " 49: 0.5052966357725069,\n",
       " 50: 0.5021319574996362,\n",
       " 51: 0.5064972856739887,\n",
       " 52: 0.5043836096080824,\n",
       " 53: 0.5160088693279674,\n",
       " 54: 0.50658924006755,\n",
       " 55: 0.4999724090405596,\n",
       " 56: 0.48603849788000436,\n",
       " 57: 0.4853264276949625,\n",
       " 58: 0.48607431983352234,\n",
       " 59: 0.5160088693279674,\n",
       " 60: 0.48920358744487946,\n",
       " 61: 0.5022130161604628,\n",
       " 62: 0.5021689856831644,\n",
       " 63: 0.5021689856831644,\n",
       " 64: 0.49780042916393463,\n",
       " 65: 0.4974258875252949,\n",
       " 66: 0.5089916291518027,\n",
       " 67: 0.5025002113886206,\n",
       " 68: 0.5146110106105182,\n",
       " 69: 0.4857582238768699,\n",
       " 70: 0.500463347986572,\n",
       " 71: 0.4856130473093521,\n",
       " 72: 0.4975352684591279,\n",
       " 73: 0.5056962194308571,\n",
       " 74: 0.5025899502013712,\n",
       " 75: 0.5118765528983962,\n",
       " 76: 0.5022385356866852,\n",
       " 77: 0.4857932312131124,\n",
       " 78: 0.4957573827321746,\n",
       " 79: 0.4976591162845665,\n",
       " 80: 0.49728023781962905,\n",
       " 81: 0.48540660941027625,\n",
       " 82: 0.5016659902314878,\n",
       " 83: 0.5020772970357196,\n",
       " 84: 0.4975213547841588,\n",
       " 85: 0.4977581579660308,\n",
       " 86: 0.5064627463128699,\n",
       " 87: 0.4974258875252949,\n",
       " 88: 0.48566902791432864,\n",
       " 89: 0.4923320724272688,\n",
       " 90: 0.5165347452908245,\n",
       " 91: 0.497829405355338,\n",
       " 92: 0.4987765670933623,\n",
       " 93: 0.48580213897979857,\n",
       " 94: 0.4850278608287902,\n",
       " 95: 0.5068865809158983,\n",
       " 96: 0.5012907411267429,\n",
       " 97: 0.5126045121824108,\n",
       " 98: 0.4856130473093521,\n",
       " 99: 0.5064993159575156,\n",
       " 100: 0.4976198134536996,\n",
       " 101: 0.4853264276949625,\n",
       " 102: 0.488686451686721,\n",
       " 103: 0.4853264276949625,\n",
       " 104: 0.4922166186808646,\n",
       " 105: 0.49724968223427407,\n",
       " 106: 0.49729859819254335,\n",
       " 107: 0.48584830999066114,\n",
       " 108: 0.5066106683564051,\n",
       " 109: 0.4889910942045292,\n",
       " 110: 0.5158696965820574,\n",
       " 111: 0.4977557786850014,\n",
       " 112: 0.5021449773904837,\n",
       " 113: 0.5061278581761404,\n",
       " 114: 0.5158696965820574,\n",
       " 115: 0.48546766117542184,\n",
       " 116: 0.5121332489104634,\n",
       " 117: 0.497539272407913,\n",
       " 118: 0.5020254981013332,\n",
       " 119: 0.5161136361179888,\n",
       " 120: 0.5068979587882314,\n",
       " 121: 0.4850698639800599,\n",
       " 122: 0.5021684741115054,\n",
       " 123: 0.49828829575703465,\n",
       " 124: 0.5039505978570654,\n",
       " 125: 0.4974258875252949,\n",
       " 126: 0.5003355362234857,\n",
       " 127: 0.5002690602269285,\n",
       " 128: 0.5122768437182459,\n",
       " 129: 0.505016423001659,\n",
       " 130: 0.4851535039708414,\n",
       " 131: 0.5042844281458204,\n",
       " 132: 0.48584830999066114,\n",
       " 133: 0.5082399613095328,\n",
       " 134: 0.5166251668890599,\n",
       " 135: 0.5087083242462345,\n",
       " 136: 0.4857582238768699,\n",
       " 137: 0.5068635920246736,\n",
       " 138: 0.5067157719782404,\n",
       " 139: 0.4856130473093521,\n",
       " 140: 0.5066527654685459,\n",
       " 141: 0.4923518261577224,\n",
       " 142: 0.502165234102513,\n",
       " 143: 0.4859574943251826,\n",
       " 144: 0.5021689856831644,\n",
       " 145: 0.5003976149254553,\n",
       " 146: 0.5164166060753839,\n",
       " 147: 0.5087238009587497,\n",
       " 148: 0.5024199489215639,\n",
       " 149: 0.5157064294164139,\n",
       " 150: 0.4850485157311097,\n",
       " 151: 0.49635353799008813,\n",
       " 152: 0.497439776426898,\n",
       " 153: 0.5061922361589368,\n",
       " 154: 0.49193632421885813,\n",
       " 155: 0.48550255468314496,\n",
       " 156: 0.5112886529395229,\n",
       " 157: 0.4926052421242045,\n",
       " 158: 0.5058601671664135,\n",
       " 159: 0.4975352684591279,\n",
       " 160: 0.5021689856831644,\n",
       " 161: 0.49759861878631423,\n",
       " 162: 0.5002690602269285,\n",
       " 163: 0.49748098995950124,\n",
       " 164: 0.5021819932303986,\n",
       " 165: 0.5021689856831644,\n",
       " 166: 0.5022001051162909,\n",
       " 167: 0.5160328584546797,\n",
       " 168: 0.4885062769387733,\n",
       " 169: 0.5153149432885707,\n",
       " 170: 0.49756158585298665,\n",
       " 171: 0.5098562533606463,\n",
       " 172: 0.5160088693279674,\n",
       " 173: 0.49322533046467326,\n",
       " 174: 0.4926052421242045,\n",
       " 175: 0.5021031080626294,\n",
       " 176: 0.4972600721207567,\n",
       " 177: 0.5084482852422226,\n",
       " 178: 0.5164166060753839,\n",
       " 179: 0.5122584630986673,\n",
       " 180: 0.5118473494164805,\n",
       " 181: 0.4859313626937177,\n",
       " 182: 0.4982514810272698,\n",
       " 183: 0.5112753778997117,\n",
       " 184: 0.5044883390397621,\n",
       " 185: 0.4933844012261847,\n",
       " 186: 0.49739188854593475,\n",
       " 187: 0.502513145470388,\n",
       " 188: 0.5090208434759793,\n",
       " 189: 0.5088398900287027,\n",
       " 190: 0.506718438886761,\n",
       " 191: 0.5127320050307457,\n",
       " 192: 0.4975352684591279,\n",
       " 193: 0.5154181242729914,\n",
       " 194: 0.5163966749173609,\n",
       " 195: 0.49772252630567865,\n",
       " 196: 0.5161631062720031,\n",
       " 197: 0.48566902791432864,\n",
       " 198: 0.49762179575450105,\n",
       " 199: 0.4889910942045292,\n",
       " 200: 0.5064677275310531,\n",
       " 201: 0.4859313626937177,\n",
       " 202: 0.5154181242729914,\n",
       " 203: 0.49773050053542023,\n",
       " 204: 0.5098233567959383,\n",
       " 205: 0.48566902791432864,\n",
       " 206: 0.48552655895772884,\n",
       " 207: 0.502079083829727,\n",
       " 208: 0.5069313351447042,\n",
       " 209: 0.48550243957506156,\n",
       " 210: 0.5164201067976508,\n",
       " 211: 0.5021689856831644,\n",
       " 212: 0.49729186841997935,\n",
       " 213: 0.5155084542713539,\n",
       " 214: 0.5024199489215639,\n",
       " 215: 0.5067103901845145,\n",
       " 216: 0.5067390326561806,\n",
       " 217: 0.5123725990670575,\n",
       " 218: 0.5038395789021258,\n",
       " 219: 0.4975352684591279,\n",
       " 220: 0.4934957479147805,\n",
       " 221: 0.5166056858838957,\n",
       " 222: 0.4920423700795769,\n",
       " 223: 0.4889910942045292,\n",
       " 224: 0.4851881859132264,\n",
       " 225: 0.49754675284336886,\n",
       " 226: 0.49737831279515854,\n",
       " 227: 0.4975352684591279,\n",
       " 228: 0.5119729505216276,\n",
       " 229: 0.5161652855961623,\n",
       " 230: 0.4934733432658229,\n",
       " 231: 0.48501185748312764,\n",
       " 232: 0.4855608883499396,\n",
       " 233: 0.49788174906950683,\n",
       " 234: 0.504706527269133,\n",
       " 235: 0.4850398496530836,\n",
       " 236: 0.4859313626937177,\n",
       " 237: 0.505894284394601,\n",
       " 238: 0.4976198134536996,\n",
       " 239: 0.497597109427822,\n",
       " 240: 0.5000748829351965,\n",
       " 241: 0.5025002113886206,\n",
       " 242: 0.49230077240974257,\n",
       " 243: 0.4854874292246123,\n",
       " 244: 0.506944819306044,\n",
       " 245: 0.4978738884477349,\n",
       " 246: 0.5160996211642699,\n",
       " 247: 0.5090208434759793,\n",
       " 248: 0.516657443549021,\n",
       " 249: 0.5066723871910083,\n",
       " 250: 0.516675599195914,\n",
       " 251: 0.4854611863081478,\n",
       " 252: 0.49332059874614836,\n",
       " 253: 0.5025589707939571,\n",
       " 254: 0.5021899730931053,\n",
       " 255: 0.48535769904181436,\n",
       " 256: 0.5090208434759793,\n",
       " 257: 0.5088679659529388,\n",
       " 258: 0.5040315209657508,\n",
       " 259: 0.49774225423309826,\n",
       " 260: 0.4855254714968397,\n",
       " 261: 0.4975242720137798,\n",
       " 262: 0.5066852048487157,\n",
       " 263: 0.4857582238768699,\n",
       " 264: 0.5023338537190376,\n",
       " 265: 0.516675599195914,\n",
       " 266: 0.5021942511015269,\n",
       " 267: 0.4975352684591279,\n",
       " 268: 0.5038952251489812,\n",
       " 269: 0.5014603455409635,\n",
       " 270: 0.4858158767659588,\n",
       " 271: 0.5021689856831644,\n",
       " 272: 0.48580213897979857,\n",
       " 273: 0.4979775925063138,\n",
       " 274: 0.5001343712732741,\n",
       " 275: 0.49728023781962905,\n",
       " 276: 0.4856130473093521,\n",
       " 277: 0.485556575693691,\n",
       " 278: 0.5022001051162909,\n",
       " 279: 0.48900886936697346,\n",
       " 280: 0.4887142786720353,\n",
       " 281: 0.49144230468794187,\n",
       " 282: 0.49796436350561973,\n",
       " 283: 0.5021819932303986,\n",
       " 284: 0.5063923411887403,\n",
       " 285: 0.4857582238768699,\n",
       " 286: 0.5088335411122702,\n",
       " 287: 0.5127775522431314,\n",
       " 288: 0.4889910942045292,\n",
       " 289: 0.48900036775116207,\n",
       " 290: 0.5085348881073901,\n",
       " 291: 0.49136082161872896,\n",
       " 292: 0.4856130473093521,\n",
       " 293: 0.4853343085078411,\n",
       " 294: 0.5038610330881678,\n",
       " 295: 0.49766261974803233,\n",
       " 296: 0.48577472055961995,\n",
       " 297: 0.5023578286504855,\n",
       " 298: 0.48566902791432864,\n",
       " 299: 0.49599500453072093,\n",
       " 300: 0.5164239172670085,\n",
       " 301: 0.5068662032188684,\n",
       " 302: 0.4962985754262882,\n",
       " 303: 0.48535769904181436,\n",
       " 304: 0.48584830999066114,\n",
       " 305: 0.5021689856831644,\n",
       " 306: 0.5163261724138872,\n",
       " 307: 0.4850174968491262,\n",
       " 308: 0.5001287733799347,\n",
       " 309: 0.5060774566336791,\n",
       " 310: 0.4853918624533338,\n",
       " 311: 0.48573317368188934,\n",
       " 312: 0.49807492774380363,\n",
       " 313: 0.48521608237101527,\n",
       " 314: 0.5163261724138872,\n",
       " 315: 0.5164166060753839,\n",
       " 316: 0.5085348881073901,\n",
       " 317: 0.5023375055282326,\n",
       " 318: 0.4856130473093521,\n",
       " 319: 0.5065656698849542,\n",
       " 320: 0.5065954649644441,\n",
       " 321: 0.5065531078159128,\n",
       " 322: 0.4885334850147175,\n",
       " 323: 0.49361875325136484,\n",
       " 324: 0.4853264276949625,\n",
       " 325: 0.5166342296946862,\n",
       " 326: 0.5021393201310997,\n",
       " 327: 0.5161136361179888,\n",
       " 328: 0.5064972856739887,\n",
       " 329: 0.5024003650177425,\n",
       " 330: 0.49204085229977057,\n",
       " 331: 0.5153240355015135,\n",
       " 332: 0.5066031018404072,\n",
       " 333: 0.5067452847544341,\n",
       " 334: 0.48501185748312764,\n",
       " 335: 0.5021737300717506,\n",
       " 336: 0.5161397937438374,\n",
       " 337: 0.5040830132359928,\n",
       " 338: 0.500463347986572,\n",
       " 339: 0.5039722279921139,\n",
       " 340: 0.5158412240889934,\n",
       " 341: 0.5040848419214141,\n",
       " 342: 0.5004773179067429,\n",
       " 343: 0.4974160349517284,\n",
       " 344: 0.48521183012972363,\n",
       " 345: 0.5020410030475702,\n",
       " 346: 0.4999931735214357,\n",
       " 347: 0.5021236085081183,\n",
       " 348: 0.497526633287363,\n",
       " 349: 0.49261168464567856,\n",
       " 350: 0.5070393933886077,\n",
       " 351: 0.4975352684591279,\n",
       " 352: 0.5164979687850194,\n",
       " 353: 0.5041189422691624,\n",
       " 354: 0.5068733105137936,\n",
       " 355: 0.4976855066688823,\n",
       " 356: 0.4856130473093521,\n",
       " 357: 0.49808513325752424,\n",
       " 358: 0.5165785781009514,\n",
       " 359: 0.5020801511942067,\n",
       " 360: 0.502079083829727,\n",
       " 361: 0.4957548916318426,\n",
       " 362: 0.5158171237486915,\n",
       " 363: 0.5165313887186316,\n",
       " 364: 0.4952076600876356,\n",
       " 365: 0.4857547875825472,\n",
       " 366: 0.49728381845372877,\n",
       " 367: 0.505917214418014,\n",
       " 368: 0.5025589707939571,\n",
       " 369: 0.4938147693985283,\n",
       " 370: 0.4885062769387733,\n",
       " 371: 0.5112886529395229,\n",
       " 372: 0.49759861878631423,\n",
       " 373: 0.5119705568439855,\n",
       " 374: 0.5024199489215639,\n",
       " 375: 0.5117211783302085,\n",
       " 376: 0.5067871681133074,\n",
       " 377: 0.49594395991659723,\n",
       " 378: 0.5065979978642389,\n",
       " 379: 0.514358071820571,\n",
       " 380: 0.5164979687850194,\n",
       " 381: 0.49746381135309176,\n",
       " 382: 0.5066528271512116,\n",
       " 383: 0.5025002113886206,\n",
       " 384: 0.4977750828794669,\n",
       " 385: 0.4931437599346649,\n",
       " 386: 0.48501185748312764,\n",
       " 387: 0.5115433699247447,\n",
       " 388: 0.49737129051154605,\n",
       " 389: 0.49609578626459316,\n",
       " 390: 0.5021689856831644,\n",
       " 391: 0.5042964810501965,\n",
       " 392: 0.49778108633514834,\n",
       " 393: 0.4889910942045292,\n",
       " 394: 0.5084482852422226,\n",
       " 395: 0.514358071820571,\n",
       " 396: 0.48528416333349517,\n",
       " 397: 0.5049961705320306,\n",
       " 398: 0.5160088693279674,\n",
       " 399: 0.48580075940278616,\n",
       " 400: 0.5048548457745015,\n",
       " 401: 0.48550243957506156,\n",
       " 402: 0.5127258129075403,\n",
       " 403: 0.49685080060067727,\n",
       " 404: 0.4921939896095591,\n",
       " 405: 0.5158171237486915,\n",
       " 406: 0.48603849788000436,\n",
       " 407: 0.49934794934945875,\n",
       " 408: 0.5165785781009514,\n",
       " 409: 0.4857582238768699,\n",
       " 410: 0.49763535999396047,\n",
       " 411: 0.5070162502918268,\n",
       " 412: 0.502247611306781,\n",
       " 413: 0.4855608883499396,\n",
       " 414: 0.508573252335471,\n",
       " 415: 0.4966557901390726,\n",
       " 416: 0.5001287733799347,\n",
       " 417: 0.4855452974123007,\n",
       " 418: 0.506479945412864,\n",
       " 419: 0.4852303021006315,\n",
       " 420: 0.5021031080626294,\n",
       " 421: 0.48510445311888845,\n",
       " 422: 0.5163261724138872,\n",
       " 423: 0.5158495254384321,\n",
       " 424: 0.4851881859132264,\n",
       " 425: 0.508573252335471,\n",
       " 426: 0.5020577709912325,\n",
       " 427: 0.5020772970357196,\n",
       " 428: 0.49801444499636033,\n",
       " 429: 0.5122250685979727,\n",
       " 430: 0.5086326894598204,\n",
       " 431: 0.5020370352886053,\n",
       " 432: 0.5157064294164139,\n",
       " 433: 0.491946798795944,\n",
       " 434: 0.4852292642665238,\n",
       " 435: 0.48526850034941915,\n",
       " 436: 0.5079287601546163,\n",
       " 437: 0.5067138787416628,\n",
       " 438: 0.5085938229486533,\n",
       " 439: 0.5002812958906518,\n",
       " 440: 0.5062168298894669,\n",
       " 441: 0.48559920352893954,\n",
       " 442: 0.4978966742625025,\n",
       " 443: 0.5165501450981086,\n",
       " 444: 0.48518187332587515,\n",
       " 445: 0.5163966749173609,\n",
       " 446: 0.4976855066688823,\n",
       " 447: 0.5164367599419759,\n",
       " 448: 0.5064284289032224,\n",
       " 449: 0.49733899343241805,\n",
       " 450: 0.5084482852422226,\n",
       " 451: 0.497597109427822,\n",
       " 452: 0.5020801511942067,\n",
       " 453: 0.48900036775116207,\n",
       " 454: 0.4850753619300866,\n",
       " 455: 0.4857932312131124,\n",
       " 456: 0.48861032688536526,\n",
       " 457: 0.5020772970357196,\n",
       " 458: 0.5153140824714226,\n",
       " 459: 0.49759861878631423,\n",
       " 460: 0.500463347986572,\n",
       " 461: 0.5020926196277704,\n",
       " 462: 0.5164593364968714,\n",
       " 463: 0.5163966749173609,\n",
       " 464: 0.48507159465146543,\n",
       " 465: 0.48584685925601945,\n",
       " 466: 0.5003355362234857,\n",
       " 467: 0.5164593364968714,\n",
       " 468: 0.497597109427822,\n",
       " 469: 0.4975352684591279,\n",
       " 470: 0.4977127850036983,\n",
       " 471: 0.4969949599834175,\n",
       " 472: 0.5067157719782404,\n",
       " 473: 0.4959492444987288,\n",
       " 474: 0.48535769904181436,\n",
       " 475: 0.5056263326814975,\n",
       " 476: 0.5065873642249845,\n",
       " 477: 0.4921939896095591,\n",
       " 478: 0.4920173423114511,\n",
       " 479: 0.49786733355006624,\n",
       " 480: 0.505745027227359,\n",
       " 481: 0.5022001051162909,\n",
       " 482: 0.5125861759614514,\n",
       " 483: 0.5085348881073901,\n",
       " 484: 0.5086483065261537,\n",
       " 485: 0.515953091021928,\n",
       " 486: 0.5025589707939571,\n",
       " 487: 0.5022001051162909,\n",
       " 488: 0.4981562953518264,\n",
       " 489: 0.4974281300070546,\n",
       " 490: 0.4856504478625923,\n",
       " 491: 0.4857582238768699,\n",
       " 492: 0.50663335578179,\n",
       " 493: 0.5022408094230172,\n",
       " 494: 0.5022408094230172,\n",
       " 495: 0.4974779548221756,\n",
       " 496: 0.5159261942198438,\n",
       " 497: 0.4902974522770423,\n",
       " 498: 0.506479945412864,\n",
       " 499: 0.50019930778241,\n",
       " 500: 0.5167640758240165,\n",
       " 501: 0.48577472055961995,\n",
       " 502: 0.5121901472777236,\n",
       " 503: 0.4918217170632696,\n",
       " 504: 0.48551977302530525,\n",
       " 505: 0.49733899343241805,\n",
       " 506: 0.5021843103702233,\n",
       " 507: 0.49762179575450105,\n",
       " 508: 0.5163497308220193,\n",
       " 509: 0.5127417210514456,\n",
       " 510: 0.5164166060753839,\n",
       " 511: 0.5080101163662215,\n",
       " 512: 0.4854874292246123,\n",
       " 513: 0.4922166186808646,\n",
       " 514: 0.497526633287363,\n",
       " 515: 0.5020772970357196,\n",
       " 516: 0.5160088693279674,\n",
       " 517: 0.506479945412864,\n",
       " 518: 0.4977127850036983,\n",
       " 519: 0.4980399029572772,\n",
       " 520: 0.4976198134536996,\n",
       " 521: 0.5165347452908245,\n",
       " 522: 0.5021689856831644,\n",
       " 523: 0.48501185748312764,\n",
       " 524: 0.48911089126481566,\n",
       " 525: 0.497367722142307,\n",
       " 526: 0.5041111707459324,\n",
       " 527: 0.4983347442078707,\n",
       " 528: 0.4999724090405596,\n",
       " 529: 0.5085555391784212,\n",
       " 530: 0.5165247709013688,\n",
       " 531: 0.5087238009587497,\n",
       " 532: 0.5065456313300154,\n",
       " 533: 0.506817022854177,\n",
       " 534: 0.5090208434759793,\n",
       " 535: 0.48860199081731165,\n",
       " 536: 0.5025589707939571,\n",
       " 537: 0.48964075657049455,\n",
       " 538: 0.5022385356866852,\n",
       " 539: 0.5021689856831644,\n",
       " 540: 0.5020695648198229,\n",
       " 541: 0.49681476662781493,\n",
       " 542: 0.500463347986572,\n",
       " 543: 0.4857582238768699,\n",
       " 544: 0.5084249599752736,\n",
       " 545: 0.4976326549031831,\n",
       " 546: 0.4982514810272698,\n",
       " 547: 0.4857547875825472,\n",
       " 548: 0.5015056153285775,\n",
       " 549: 0.4856504478625923,\n",
       " 550: 0.5021449773904837,\n",
       " 551: 0.4978726672768536,\n",
       " 552: 0.4924100228459682,\n",
       " 553: 0.4977380291861657,\n",
       " 554: 0.48566902791432864,\n",
       " 555: 0.4851024389910019,\n",
       " 556: 0.5163497308220193,\n",
       " 557: 0.5022713865026516,\n",
       " 558: 0.5067296338647368,\n",
       " 559: 0.508808854180754,\n",
       " 560: 0.5067965957154132,\n",
       " 561: 0.5023338537190376,\n",
       " 562: 0.5020577709912325,\n",
       " 563: 0.5024458289308298,\n",
       " 564: 0.5002699596050623,\n",
       " 565: 0.48511851588237564,\n",
       " 566: 0.5082361887654346,\n",
       " 567: 0.4977507764791264,\n",
       " 568: 0.4975352684591279,\n",
       " 569: 0.497439776426898,\n",
       " 570: 0.4859574943251826,\n",
       " 571: 0.5023645039953357,\n",
       " 572: 0.49230077240974257,\n",
       " 573: 0.4978425943312845,\n",
       " 574: 0.48573317368188934,\n",
       " 575: 0.4901920718474379,\n",
       " 576: 0.49222976886125785,\n",
       " 577: 0.5127149533990948,\n",
       " 578: 0.4935988062489603,\n",
       " 579: 0.49745673653118055,\n",
       " 580: 0.48603849788000436,\n",
       " 581: 0.49769592969733845,\n",
       " 582: 0.48546766117542184,\n",
       " 583: 0.508573252335471,\n",
       " 584: 0.5024199489215639,\n",
       " 585: 0.5078145750782472,\n",
       " 586: 0.4893333116568319,\n",
       " 587: 0.4932422824304549,\n",
       " 588: 0.5066260487235121,\n",
       " 589: 0.508573252335471,\n",
       " 590: 0.4850753619300866,\n",
       " 591: 0.5119903271782994,\n",
       " 592: 0.5119277877902209,\n",
       " 593: 0.49735814823544433,\n",
       " 594: 0.48580213897979857,\n",
       " 595: 0.5065376086879653,\n",
       " 596: 0.5021689856831644,\n",
       " 597: 0.5159971137823609,\n",
       " 598: 0.5128005106998734,\n",
       " 599: 0.5022467801120339,\n",
       " 600: 0.5057131804517134,\n",
       " 601: 0.5021319574996362,\n",
       " 602: 0.49686086777090965,\n",
       " 603: 0.5020254981013332,\n",
       " 604: 0.5022385356866852,\n",
       " 605: 0.5065854616724226,\n",
       " 606: 0.5016593507487819,\n",
       " 607: 0.49774225423309826,\n",
       " 608: 0.5085630885445747,\n",
       " 609: 0.4850698639800599,\n",
       " 610: 0.4919548793737451,\n",
       " 611: 0.5065656698849542,\n",
       " 612: 0.49221693898906804,\n",
       " 613: 0.4975352684591279,\n",
       " 614: 0.5084482852422226,\n",
       " 615: 0.4852303021006315,\n",
       " 616: 0.5156570982513078,\n",
       " 617: 0.5042716628057967,\n",
       " 618: 0.49768185873354254,\n",
       " 619: 0.50019930778241,\n",
       " 620: 0.49186953210736956,\n",
       " 621: 0.4853156056029678,\n",
       " 622: 0.4973453486014953,\n",
       " 623: 0.5023130477344315,\n",
       " 624: 0.511794656515,\n",
       " 625: 0.5087829002868478,\n",
       " 626: 0.5025589707939571,\n",
       " 627: 0.49784634454977456,\n",
       " 628: 0.49821872712261867,\n",
       " 629: 0.5153140824714226,\n",
       " 630: 0.5041607203105315,\n",
       " 631: 0.4972680397663585,\n",
       " 632: 0.4856608653635109,\n",
       " 633: 0.5063301354630296,\n",
       " 634: 0.49186953210736956,\n",
       " 635: 0.49750591880797396,\n",
       " 636: 0.5056147688389805,\n",
       " 637: 0.508808854180754,\n",
       " 638: 0.48548565389278336,\n",
       " 639: 0.5020410030475702,\n",
       " 640: 0.5084482852422226,\n",
       " 641: 0.4857582238768699,\n",
       " 642: 0.497497258277122,\n",
       " 643: 0.4856333998663235,\n",
       " 644: 0.5021689856831644,\n",
       " 645: 0.49747422848403916,\n",
       " 646: 0.49228680494967253,\n",
       " 647: 0.48900036775116207,\n",
       " 648: 0.4857582238768699,\n",
       " 649: 0.5052203374807537,\n",
       " 650: 0.48525647341765876,\n",
       " 651: 0.5020857130027375,\n",
       " 652: 0.5040766919191131,\n",
       " 653: 0.5021825865737846,\n",
       " 654: 0.4973141683788556,\n",
       " 655: 0.5021689856831644,\n",
       " 656: 0.48580213897979857,\n",
       " 657: 0.5087829002868478,\n",
       " 658: 0.4858076354055543,\n",
       " 659: 0.512054889184712,\n",
       " 660: 0.48566902791432864,\n",
       " 661: 0.5041970231249122,\n",
       " 662: 0.5111200276231627,\n",
       " 663: 0.49221693898906804,\n",
       " 664: 0.49230077240974257,\n",
       " 665: 0.5000821760628843,\n",
       " 666: 0.4979306290616141,\n",
       " 667: 0.5049445314718756,\n",
       " 668: 0.5056154415551815,\n",
       " 669: 0.48900036775116207,\n",
       " 670: 0.5024199489215639,\n",
       " 671: 0.4974476965751133,\n",
       " 672: 0.5024199489215639,\n",
       " 673: 0.485327734138958,\n",
       " 674: 0.5120210824781486,\n",
       " 675: 0.4852303021006315,\n",
       " 676: 0.512531943032279,\n",
       " 677: 0.497557586323095,\n",
       " 678: 0.5140586815480043,\n",
       " 679: 0.4934098752225625,\n",
       " 680: 0.516810872765397,\n",
       " 681: 0.48900036775116207,\n",
       " 682: 0.5020313157713677,\n",
       " 683: 0.5052733816076221,\n",
       " 684: 0.48546766117542184,\n",
       " 685: 0.4977507764791264,\n",
       " 686: 0.48566902791432864,\n",
       " 687: 0.49307870459076947,\n",
       " 688: 0.5118196764801703,\n",
       " 689: 0.502165234102513,\n",
       " 690: 0.5022001051162909,\n",
       " 691: 0.4853264276949625,\n",
       " 692: 0.49733719578082003,\n",
       " 693: 0.5086688672393543,\n",
       " 694: 0.5098547171140163,\n",
       " 695: 0.5057131804517134,\n",
       " 696: 0.5020410030475702,\n",
       " 697: 0.5065089820728675,\n",
       " 698: 0.493688473598623,\n",
       " 699: 0.49211468056300867,\n",
       " 700: 0.5021689856831644,\n",
       " 701: 0.48559920352893954,\n",
       " 702: 0.48518639731296875,\n",
       " 703: 0.497347572753017,\n",
       " 704: 0.5022385356866852,\n",
       " 705: 0.4974519251744379,\n",
       " 706: 0.4983347442078707,\n",
       " 707: 0.4976198134536996,\n",
       " 708: 0.5022408094230172,\n",
       " 709: 0.5068092939543167,\n",
       " 710: 0.5004178381397193,\n",
       " 711: 0.5046476918595282,\n",
       " 712: 0.5160121802379303,\n",
       " 713: 0.502185310291645,\n",
       " 714: 0.48577472055961995,\n",
       " 715: 0.512061296425163,\n",
       " 716: 0.4923518261577224,\n",
       " 717: 0.4977749159797695,\n",
       " 718: 0.5085751934187616,\n",
       " 719: 0.4973566572382286,\n",
       " 720: 0.4889910942045292,\n",
       " 721: 0.485556575693691,\n",
       " 722: 0.4927241779007751,\n",
       " 723: 0.5098332510421694,\n",
       " 724: 0.4977581579660308,\n",
       " 725: 0.4896070564700128,\n",
       " 726: 0.5046584296369881,\n",
       " 727: 0.5118223036029126,\n",
       " 728: 0.48550255468314496,\n",
       " 729: 0.49230077240974257,\n",
       " 730: 0.4923518261577224,\n",
       " 731: 0.48854079101800335,\n",
       " 732: 0.5022408094230172,\n",
       " 733: 0.49828829575703465,\n",
       " 734: 0.4980518951123467,\n",
       " 735: 0.4931395289731706,\n",
       " 736: 0.48552001812967904,\n",
       " 737: 0.48603849788000436,\n",
       " 738: 0.5067191634941739,\n",
       " 739: 0.48526850034941915,\n",
       " 740: 0.4856504478625923,\n",
       " 741: 0.4934764821241209,\n",
       " 742: 0.5164593364968714,\n",
       " 743: 0.49745673653118055,\n",
       " 744: 0.49739188854593475,\n",
       " 745: 0.48526850034941915,\n",
       " 746: 0.5042844281458204,\n",
       " 747: 0.48958625148629437,\n",
       " 748: 0.5126320200833014,\n",
       " 749: 0.5163975157991842,\n",
       " 750: 0.48846790417414365,\n",
       " 751: 0.49230077240974257,\n",
       " 752: 0.49745673653118055,\n",
       " 753: 0.49660627930809753,\n",
       " 754: 0.48533647748816944,\n",
       " 755: 0.5070512253491949,\n",
       " 756: 0.4976198134536996,\n",
       " 757: 0.5043836096080824,\n",
       " 758: 0.5020772970357196,\n",
       " 759: 0.5024199489215639,\n",
       " 760: 0.5117262283847444,\n",
       " 761: 0.4853264276949625,\n",
       " 762: 0.49230077240974257,\n",
       " 763: 0.5039313585470828,\n",
       " 764: 0.48603849788000436,\n",
       " 765: 0.49211468056300867,\n",
       " 766: 0.5021942511015269,\n",
       " 767: 0.485658378738791,\n",
       " 768: 0.5001287733799347,\n",
       " 769: 0.49221251604636307,\n",
       " 770: 0.509596534666515,\n",
       " 771: 0.48506347712040115,\n",
       " 772: 0.5023578286504855,\n",
       " 773: 0.4855608883499396,\n",
       " 774: 0.4973832316188492,\n",
       " 775: 0.4923659753103342,\n",
       " 776: 0.5000140783482477,\n",
       " 777: 0.49771298497192706,\n",
       " 778: 0.5085555391784212,\n",
       " 779: 0.5086303473309666,\n",
       " 780: 0.49230077240974257,\n",
       " 781: 0.502165234102513,\n",
       " 782: 0.5084482852422226,\n",
       " 783: 0.5013912781490494,\n",
       " 784: 0.5084965963120206,\n",
       " 785: 0.5024089575317457,\n",
       " 786: 0.4977581579660308,\n",
       " 787: 0.4857582238768699,\n",
       " 788: 0.49230077240974257,\n",
       " 789: 0.5025589707939571,\n",
       " 790: 0.5090208434759793,\n",
       " 791: 0.4981083949364653,\n",
       " 792: 0.4923693616266705,\n",
       " 793: 0.5063730455170192,\n",
       " 794: 0.4856504478625923,\n",
       " 795: 0.49795355441281114,\n",
       " 796: 0.499256170381678,\n",
       " 797: 0.48580213897979857,\n",
       " 798: 0.4857932312131124,\n",
       " 799: 0.5021031080626294,\n",
       " 800: 0.4926052421242045,\n",
       " 801: 0.5107951338488201,\n",
       " 802: 0.48510445311888845,\n",
       " 803: 0.5022130161604628,\n",
       " 804: 0.4975352684591279,\n",
       " 805: 0.49228680494967253,\n",
       " 806: 0.4936920455301968,\n",
       " 807: 0.4923518261577224,\n",
       " 808: 0.4855608883499396,\n",
       " 809: 0.4859393361746739,\n",
       " 810: 0.4897004040349381,\n",
       " 811: 0.5023375055282326,\n",
       " 812: 0.48603849788000436,\n",
       " 813: 0.4855459175228407,\n",
       " 814: 0.49773050053542023,\n",
       " 815: 0.4857582238768699,\n",
       " 816: 0.50019930778241,\n",
       " 817: 0.5156686938903456,\n",
       " 818: 0.5166310378366176,\n",
       " 819: 0.5021031080626294,\n",
       " 820: 0.5040192876886842,\n",
       " 821: 0.5022001051162909,\n",
       " 822: 0.5021080226982018,\n",
       " 823: 0.508880275729916,\n",
       " 824: 0.5021689856831644,\n",
       " 825: 0.508573252335471,\n",
       " 826: 0.4977750828794669,\n",
       " 827: 0.4857547875825472,\n",
       " 828: 0.49729099080906114,\n",
       " 829: 0.5152997131332762,\n",
       " 830: 0.48537907200862557,\n",
       " 831: 0.48603849788000436,\n",
       " 832: 0.49824391510293564,\n",
       " 833: 0.4975581407770429,\n",
       " 834: 0.5025589707939571,\n",
       " 835: 0.4857547875825472,\n",
       " 836: 0.497526633287363,\n",
       " 837: 0.5166342296946862,\n",
       " 838: 0.5021843103702233,\n",
       " 839: 0.4856333998663235,\n",
       " 840: 0.5003114864402192,\n",
       " 841: 0.5025589707939571,\n",
       " 842: 0.5015608510326589,\n",
       " 843: 0.5022001051162909,\n",
       " 844: 0.49745673653118055,\n",
       " 845: 0.4850278608287902,\n",
       " 846: 0.4980261189918395,\n",
       " 847: 0.4855608883499396,\n",
       " 848: 0.48955081365998004,\n",
       " 849: 0.4976021422474514,\n",
       " 850: 0.49792636802403234,\n",
       " 851: 0.5107260829152869,\n",
       " 852: 0.5118240102234908,\n",
       " 853: 0.5046818168416773,\n",
       " 854: 0.4891093009475445,\n",
       " 855: 0.48900036775116207,\n",
       " 856: 0.516810872765397,\n",
       " 857: 0.5062361811837064,\n",
       " 858: 0.512703014312745,\n",
       " 859: 0.5023254458265158,\n",
       " 860: 0.5070213140150606,\n",
       " 861: 0.5154181242729914,\n",
       " 862: 0.4850174968491262,\n",
       " 863: 0.4999724090405596,\n",
       " 864: 0.48848745212827627,\n",
       " 865: 0.5004053710640769,\n",
       " 866: 0.5166666295523851,\n",
       " 867: 0.5046694956689703,\n",
       " 868: 0.5025589707939571,\n",
       " 869: 0.4857582238768699,\n",
       " 870: 0.4979618330791524,\n",
       " 871: 0.5023578286504855,\n",
       " 872: 0.4857582238768699,\n",
       " 873: 0.5001034540548248,\n",
       " 874: 0.5160088693279674,\n",
       " 875: 0.4857932312131124,\n",
       " 876: 0.5021236085081183,\n",
       " 877: 0.48970422004065595,\n",
       " 878: 0.50649037209963,\n",
       " 879: 0.5060026529656831,\n",
       " 880: 0.5057743755497623,\n",
       " 881: 0.508522764322975,\n",
       " 882: 0.5064284289032224,\n",
       " 883: 0.48855124362145513,\n",
       " 884: 0.4850698639800599,\n",
       " 885: 0.4936920455301968,\n",
       " 886: 0.497439776426898,\n",
       " 887: 0.5121399056003323,\n",
       " 888: 0.49213976453722236,\n",
       " 889: 0.497597109427822,\n",
       " 890: 0.5165347452908245,\n",
       " 891: 0.5022715549824668,\n",
       " 892: 0.48603849788000436,\n",
       " 893: 0.5046111128252214,\n",
       " 894: 0.48546766117542184,\n",
       " 895: 0.5086792171515879,\n",
       " 896: 0.4968203232997973,\n",
       " 897: 0.4981314104982168,\n",
       " 898: 0.5017908356129184,\n",
       " 899: 0.4857932312131124,\n",
       " 900: 0.5002444733966269,\n",
       " 901: 0.48603849788000436,\n",
       " 902: 0.49762210587420047,\n",
       " 903: 0.5160088693279674,\n",
       " 904: 0.49766261974803233,\n",
       " 905: 0.5005165582594336,\n",
       " 906: 0.5128228079358804,\n",
       " 907: 0.4977758695874114,\n",
       " 908: 0.5021689856831644,\n",
       " 909: 0.5022001051162909,\n",
       " 910: 0.5085765282546588,\n",
       " 911: 0.4977373602733348,\n",
       " 912: 0.5107886587308198,\n",
       " 913: 0.5022719580114302,\n",
       " 914: 0.5071372752650369,\n",
       " 915: 0.5022459817677906,\n",
       " 916: 0.4974160349517284,\n",
       " 917: 0.5020685563323477,\n",
       " 918: 0.5161631062720031,\n",
       " 919: 0.5023392845860034,\n",
       " 920: 0.5024199489215639,\n",
       " 921: 0.5015309184330364,\n",
       " 922: 0.4977750828794669,\n",
       " 923: 0.5026439329026382,\n",
       " 924: 0.4918259738599519,\n",
       " 925: 0.5070384851718366,\n",
       " 926: 0.5018714306832387,\n",
       " 927: 0.5058447265878421,\n",
       " 928: 0.4979319882569348,\n",
       " 929: 0.5021689856831644,\n",
       " 930: 0.5087158126281168,\n",
       " 931: 0.5163719993820634,\n",
       " 932: 0.5022715549824668,\n",
       " 933: 0.49870315124238523,\n",
       " 934: 0.504478554171824,\n",
       " 935: 0.5164367599419759,\n",
       " 936: 0.4976198134536996,\n",
       " 937: 0.4974436705663117,\n",
       " 938: 0.49395260798173685,\n",
       " 939: 0.48851131797544617,\n",
       " 940: 0.49747268296944225,\n",
       " 941: 0.4854451994965634,\n",
       " 942: 0.48895591669933713,\n",
       " 943: 0.4856504478625923,\n",
       " 944: 0.48895591669933713,\n",
       " 945: 0.5065429741780357,\n",
       " 946: 0.4851676875757382,\n",
       " 947: 0.4857582238768699,\n",
       " 948: 0.5021236085081183,\n",
       " 949: 0.5023645039953357,\n",
       " 950: 0.511895565987223,\n",
       " 951: 0.5020695648198229,\n",
       " 952: 0.5022385356866852,\n",
       " 953: 0.5022001051162909,\n",
       " 954: 0.49814897525380836,\n",
       " 955: 0.5067621627756921,\n",
       " 956: 0.5058950225347268,\n",
       " 957: 0.4891093009475445,\n",
       " 958: 0.5023254458265158,\n",
       " 959: 0.4879710394410605,\n",
       " 960: 0.4980261189918395,\n",
       " 961: 0.48521608237101527,\n",
       " 962: 0.5022001051162909,\n",
       " 963: 0.4976289514516416,\n",
       " 964: 0.4926052421242045,\n",
       " 965: 0.5021220307353146,\n",
       " 966: 0.4977507764791264,\n",
       " 967: 0.5087829002868478,\n",
       " 968: 0.5022408094230172,\n",
       " 969: 0.5010431731562315,\n",
       " 970: 0.4858158767659588,\n",
       " 971: 0.4888908646444367,\n",
       " 972: 0.4976198134536996,\n",
       " 973: 0.49995805914750263,\n",
       " 974: 0.49746381135309176,\n",
       " 975: 0.5130436735484075,\n",
       " 976: 0.5022408094230172,\n",
       " 977: 0.4975363915969865,\n",
       " 978: 0.5064284289032224,\n",
       " 979: 0.4857547875825472,\n",
       " 980: 0.5006620971433058,\n",
       " 981: 0.4923518261577224,\n",
       " 982: 0.5067722927544078,\n",
       " 983: 0.4852303021006315,\n",
       " 984: 0.5001034540548248,\n",
       " 985: 0.4918479530281825,\n",
       " 986: 0.4857582238768699,\n",
       " 987: 0.49227540014929355,\n",
       " 988: 0.5124789456259196,\n",
       " 989: 0.4976790694252594,\n",
       " 990: 0.5021843103702233,\n",
       " 991: 0.4975352732947403,\n",
       " 992: 0.5022385356866852,\n",
       " 993: 0.5005377226416821,\n",
       " 994: 0.5085555391784212,\n",
       " 995: 0.508127747474051,\n",
       " 996: 0.49685080060067727,\n",
       " 997: 0.5021819932303986,\n",
       " 998: 0.4973832316188492,\n",
       " 999: 0.5082354360443302,\n",
       " ...}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15806199967539436"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total[1]/(total[0]+total[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
