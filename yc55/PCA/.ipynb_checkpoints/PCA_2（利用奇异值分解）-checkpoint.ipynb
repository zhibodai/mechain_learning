{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33333333],\n",
       "       [-0.25      , -0.16666667],\n",
       "       [ 0.25      ,  0.16666667],\n",
       "       [ 0.5       ,  0.66666667],\n",
       "       [-0.5       , -0.33333333]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.array([[3,2000],\n",
    "            [2,3000],\n",
    "            [4,5000],\n",
    "            [5,8000],\n",
    "            [1,2000]],dtype='float')\n",
    "\n",
    "#数据归一化\n",
    "mean=np.mean(A,axis=0)\n",
    "norm=A-mean\n",
    "# 数据缩放\n",
    "scope=np.max(norm,axis=0) - np.min(norm,axis=0)\n",
    "norm=norm/scope\n",
    "norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA算法模拟:利用奇异值分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.625     ,  0.58333333],\n",
       "       [ 0.58333333,  0.72222222]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算协方差矩阵\n",
    "C=np.dot(norm.T,norm)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.67710949, -0.73588229],\n",
       "       [-0.73588229,  0.67710949]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对待下列方差矩阵进行奇异值分解  得到特征向量  U\n",
    "U,S,V=np.linalg.svd(C)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.67710949],\n",
       "       [-0.73588229]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#因为要将二维转一维  所以只取特征矩阵的第一列来构造主成分矩阵\n",
    "U_reduce=U[:,0].reshape(2,1)\n",
    "U_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2452941 ],\n",
       "       [ 0.29192442],\n",
       "       [-0.29192442],\n",
       "       [-0.82914294],\n",
       "       [ 0.58384884]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#利用主成分特征矩阵来进行降维处理  得到的结果是一个一维矩阵\n",
    "Z = np.dot(norm,U_reduce)\n",
    "Z"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "也可以照PCA数据恢复的计算公式完成数据的近似恢复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16609096, -0.18050758],\n",
       "       [-0.19766479, -0.21482201],\n",
       "       [ 0.19766479,  0.21482201],\n",
       "       [ 0.56142055,  0.6101516 ],\n",
       "       [-0.39532959, -0.42964402]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xapprox=np.dot(Z,U_reduce.T)\n",
    "Xapprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.33563616e+00,   2.91695452e+03],\n",
       "       [  2.20934082e+00,   2.71106794e+03],\n",
       "       [  3.79065918e+00,   5.28893206e+03],\n",
       "       [  5.24568220e+00,   7.66090960e+03],\n",
       "       [  1.41868164e+00,   1.42213588e+03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(Xapprox,scope)+mean   #乘 缩放比   +  均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用  sklearn  实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2452941 ],\n",
       "       [-0.29192442],\n",
       "       [ 0.29192442],\n",
       "       [ 0.82914294],\n",
       "       [-0.58384884]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "n=1\n",
    "scaler=MinMaxScaler()\n",
    "arr=scaler.fit_transform(A)\n",
    "\n",
    "pca=PCA( n_components=n)\n",
    "R2=pca.fit_transform(arr)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保留的成分个数: 1\n",
      "特征的方差: [[ 0.67710949  0.73588229]]\n",
      "保留的 1 个成分,降维后的各主成分的方差值占总方差值的比例,这个比例越大，则越是重要的主要分 [ 0.93449053]\n",
      "代表降维后的各成分的方差值。方差值越大，则说明越是重要的主成分 [ 0.3147416]\n"
     ]
    }
   ],
   "source": [
    "#输出其他结果\n",
    "\n",
    "print('保留的成分个数:',pca.n_components_)\n",
    "print('特征的方差:',pca.components_)\n",
    "#  代表降维后的各成分的方差值占总方差的比例  这个比例越大，则越是重要的主要成分\n",
    "print('保留的',n,'个成分,降维后的各主成分的方差值占总方差值的比例,这个比例越大，则越是重要的主要分',pca.explained_variance_ratio_)\n",
    "print('代表降维后的各成分的方差值。方差值越大，则说明越是重要的主成分',pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2452941 ],\n",
       "       [-0.29192442],\n",
       "       [ 0.29192442],\n",
       "       [ 0.82914294],\n",
       "       [-0.58384884]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def std_PCA(**argv):\n",
    "    '''\n",
    "    利用管道进行数据缩放后加入到PCA处理\n",
    "    '''\n",
    "    scaler = MinMaxScaler()\n",
    "    pca=PCA(**argv)\n",
    "    pipeline=Pipeline([('scaler',scaler),('pca',pca)])\n",
    "    return pipeline\n",
    "\n",
    "pca=std_PCA(n_components=1)\n",
    "R3 = pca.fit_transform(A)\n",
    "R3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.33563616e+00,   2.91695452e+03],\n",
       "       [  2.20934082e+00,   2.71106794e+03],\n",
       "       [  3.79065918e+00,   5.28893206e+03],\n",
       "       [  5.24568220e+00,   7.66090960e+03],\n",
       "       [  1.41868164e+00,   1.42213588e+03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.inverse_transform(R2)   #再恢复成近似的原值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "plt.figure(figsize=(5,5),dpi=144)\n",
    "plt.title('PCA的物理意义',fontproperties=myfont)\n",
    "\n",
    "ymin=xmin=-1\n",
    "ymax=xmax=1\n",
    "plt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA算法模拟:2.计算特征值和特征向量来实现降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征值 [  6.15384437e-01   6.50000188e+06]\n",
      "特征向量 [[ -9.99999855e-01  -5.38461511e-04]\n",
      " [  5.38461511e-04  -9.99999855e-01]]\n"
     ]
    }
   ],
   "source": [
    "#过程演示\n",
    "meanValues=np.mean(norm,axis=0)\n",
    "meanRemoved=A-meanValues\n",
    "#numpy中的matrix是ndarray子类\n",
    "# matrix.getA  -》 ndarray\n",
    "covValues=np.cov(meanRemoved,rowvar=0)  #协方差矩阵\n",
    "eigValues,eigVectors=np.linalg.eig( np.mat(covValues) )  #求特征值和特征向量\n",
    "print('特征值',eigValues)\n",
    "print('特征向量',eigVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pca 封装函数\n",
    "def pca(dataMatrics,topNfeat=4096):\n",
    "    '''\n",
    "    dataMatrics  待降维矩阵\n",
    "    topNfeat    要保留的特征数\n",
    "    '''\n",
    "    #求数据矩阵每一列的均值\n",
    "    meanValues=np.mean(dataMatrics,axis=0)\n",
    "    #数据矩阵每一列特征减去该列的特征均值\n",
    "    meanRemoved=dataMatrics-meanValues\n",
    "    #计算协方差矩阵，除数n-1是为了得到协方差的无偏估计\n",
    "    #  cov(x,0)=cov(x)  除数  n-1  （n为样本个数）\n",
    "    #  cov(x,1)  除数是n\n",
    "    covMatrics=np.cov(meanRemoved,rowvar=0)\n",
    "    #计算协方差矩阵的特征值及其对应的特征向量均保持在相应的矩阵中\n",
    "    eigValues,eigVectors=np.linalg.eig(np.mat(covMatrics) )\n",
    "    #sort()  对特征值矩阵排序(由小到大)\n",
    "    #argsort(): 对特征值矩阵进行由小到大排序  返回对应排序后的索引\n",
    "    eigValInd=np.argsort(eigValues)\n",
    "    #从排好序的矩阵最后一个开始自下而上选取最大的N个特征值  返回其对应的索引\n",
    "    eigValInd=eigValInd[:-(topNfeat+1):-1]\n",
    "    #将特征值最大的N个特征值对应索引的特征向量提取出来，组成亚索矩阵\n",
    "    redEigVects=eigVectors[:,eigValInd]\n",
    "    #将去除均值后的   数据矩阵*压缩矩阵  转换到新的空间，使维度降低到N\n",
    "    lowDDataMatrics=meanRemoved*redEigVects\n",
    "    #利用降维后的矩阵反构出原数据矩阵\n",
    "    recoverMat=(lowDDataMatrics*redEigVects.T)+meanValues\n",
    "    #返回值：降维后的低维矩阵,还原的矩阵\n",
    "    return lowDDataMatrics,recoverMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2452941 ]\n",
      " [ 0.29192442]\n",
      " [-0.29192442]\n",
      " [-0.82914294]\n",
      " [ 0.58384884]]\n",
      "[[-0.16609096 -0.18050758]\n",
      " [-0.19766479 -0.21482201]\n",
      " [ 0.19766479  0.21482201]\n",
      " [ 0.56142055  0.6101516 ]\n",
      " [-0.39532959 -0.42964402]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[  2.33563616e+00,   2.91695452e+03],\n",
       "        [  2.20934082e+00,   2.71106794e+03],\n",
       "        [  3.79065918e+00,   5.28893206e+03],\n",
       "        [  5.24568220e+00,   7.66090960e+03],\n",
       "        [  1.41868164e+00,   1.42213588e+03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newMat,recoverMat=pca(norm,1)\n",
    "print(newMat)\n",
    "print(recoverMat)\n",
    "recoverMat=np.multiply(recoverMat,scope)+mean\n",
    "recoverMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
