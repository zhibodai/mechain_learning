{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#sklearn.datasets 里面调入波士顿房价的数据\n",
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()\n",
    "# sklearn.cross_validation 导入数据分割器\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "#采用随机采样的方法\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.32000000e-03   1.80000000e+01   2.31000000e+00 ...,   1.53000000e+01\n",
      "    3.96900000e+02   4.98000000e+00]\n",
      " [  2.73100000e-02   0.00000000e+00   7.07000000e+00 ...,   1.78000000e+01\n",
      "    3.96900000e+02   9.14000000e+00]\n",
      " [  2.72900000e-02   0.00000000e+00   7.07000000e+00 ...,   1.78000000e+01\n",
      "    3.92830000e+02   4.03000000e+00]\n",
      " ..., \n",
      " [  6.07600000e-02   0.00000000e+00   1.19300000e+01 ...,   2.10000000e+01\n",
      "    3.96900000e+02   5.64000000e+00]\n",
      " [  1.09590000e-01   0.00000000e+00   1.19300000e+01 ...,   2.10000000e+01\n",
      "    3.93450000e+02   6.48000000e+00]\n",
      " [  4.74100000e-02   0.00000000e+00   1.19300000e+01 ...,   2.10000000e+01\n",
      "    3.96900000e+02   7.88000000e+00]]\n",
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大值: 50.0\n",
      "最小值: 5.0\n",
      "平均值: 22.5328063241\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据分析\n",
    "\n",
    "#分析回归目标值的差异\n",
    "print('最大值:',np.max(boston.target))\n",
    "print('最小值:',np.min(boston.target))\n",
    "print('平均值:',np.mean(boston.target))\n",
    "\n",
    "#补充  数据集的分析\n",
    "from pandas import pandas as pd\n",
    "df=pd.DataFrame(boston.data)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据 [[-1.0856306   0.99734545  0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654 -2.42667924 -0.42891263]\n",
      " [ 1.26593626 -0.8667404  -0.67888615 -0.09470897]\n",
      " [ 1.49138963 -0.638902   -0.44398196 -0.43435128]\n",
      " [ 2.20593008  2.18678609  1.0040539   0.3861864 ]]\n",
      "转换后数据 [[-0.94511643  0.58665507  0.5223171  -0.93064483]\n",
      " [-0.53659117  1.16247784 -2.13366794  0.06768082]\n",
      " [ 0.9495916  -1.05437488 -0.42049501  0.3773612 ]\n",
      " [ 1.13124423 -0.85379954 -0.19024378  0.06264126]\n",
      " [ 1.70696485  1.63376764  1.22910949  0.8229693 ]]\n",
      "转换后的数据的均值:[ 0.08737571  0.33094968 -0.24989369 -0.50195303],方差:[ 1.54038781  1.29032409  1.04082479  1.16464894]\n",
      "还可以转换回来的值 [[-1.0856306   0.99734545  0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654 -2.42667924 -0.42891263]\n",
      " [ 1.26593626 -0.8667404  -0.67888615 -0.09470897]\n",
      " [ 1.49138963 -0.638902   -0.44398196 -0.43435128]\n",
      " [ 2.20593008  2.18678609  1.0040539   0.3861864 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler  #标准化处理\n",
    "\n",
    "#StandardScaler  去均值和方差\n",
    "np.random.seed(123)\n",
    "data=np.random.randn(10,4)   #10行 4列\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "train_data=scaler.transform(data)\n",
    "#  train_data=scaler.fit_transform(data)  上面2步的合集\n",
    "print('原始数据',data[0:5])\n",
    "print('转换后数据',train_data[0:5])\n",
    "print('转换后的数据的均值:{},方差:{}'.format(scaler.mean_,scaler.var_))\n",
    "print('还可以转换回来的值',scaler.inverse_transform(train_data)[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均值:[ 0.08737571  0.33094968 -0.24989369 -0.50195303]，标准差:[ 1.24112361  1.13592433  1.02020821  1.07918902]，方差:[ 1.54038781  1.29032409  1.04082479  1.16464894]\n",
      "自定义的StandardScaler:[[-0.94511643  0.58665507  0.5223171  -0.93064483]\n",
      " [-0.53659117  1.16247784 -2.13366794  0.06768082]\n",
      " [ 0.9495916  -1.05437488 -0.42049501  0.3773612 ]\n",
      " [ 1.13124423 -0.85379954 -0.19024378  0.06264126]\n",
      " [ 1.70696485  1.63376764  1.22910949  0.8229693 ]\n",
      " [ 0.52371324  1.02100318 -0.67235312  1.55466934]\n",
      " [-1.08067913 -0.85278672  1.13408114 -0.858726  ]\n",
      " [-0.18325687 -1.04998594 -0.00561227 -2.1281129 ]\n",
      " [-1.49776284 -0.9074785   1.15403514  0.30422599]\n",
      " [-0.06810748  0.31452186 -0.61717074  0.72793583]]\n",
      "++++++++++=====================\n",
      "转换回来的数据:[[-1.0856306   0.99734545  0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654 -2.42667924 -0.42891263]\n",
      " [ 1.26593626 -0.8667404  -0.67888615 -0.09470897]\n",
      " [ 1.49138963 -0.638902   -0.44398196 -0.43435128]\n",
      " [ 2.20593008  2.18678609  1.0040539   0.3861864 ]\n",
      " [ 0.73736858  1.49073203 -0.93583387  1.17582904]\n",
      " [-1.25388067 -0.6377515   0.9071052  -1.4286807 ]\n",
      " [-0.14006872 -0.8617549  -0.25561937 -2.79858911]\n",
      " [-1.7715331  -0.69987723  0.92746243 -0.17363568]\n",
      " [ 0.00284592  0.68822271 -0.87953634  0.28362732]]\n",
      "均值:[ -1.52655666e-17   8.88178420e-17   1.11022302e-17  -1.55431223e-16]方差:[ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#自定义实现    StandardScaler\n",
    "mean=np.mean(data,axis=0)\n",
    "std=np.std(data,axis=0)  #标准差\n",
    "var= std * std  #方差\n",
    "print('均值:{}，标准差:{}，方差:{}'.format(mean,std,var))\n",
    "\n",
    "#numpy的广播功能  data - mean\n",
    "another_trans_data=data-mean\n",
    "# 除以标准差\n",
    "another_trans_data=another_trans_data/std\n",
    "print('自定义的StandardScaler:{}'.format(another_trans_data))\n",
    "print('++++++++++=====================')\n",
    "\n",
    "\n",
    "\n",
    "#转换回来\n",
    "origin=another_trans_data*std+mean\n",
    "print('转换回来的数据:{}'.format(origin))\n",
    "\n",
    "#观察StandardScaler的特点  均值 0 方差 1\n",
    "mean=np.mean(another_trans_data,axis=0)\n",
    "std=np.std(another_trans_data,axis=0)\n",
    "var=std * std\n",
    "print('均值:{}方差:{}'.format(mean,var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从 sklearn.perprocessing 导入数据标准化模块\n",
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "\n",
    "X_scaler=StandardScaler()\n",
    "X=X_scaler.fit_transform(X)\n",
    "\n",
    "y=np.array(y).reshape(-1,1)\n",
    "y_scaler=StandardScaler()\n",
    "y=y_scaler.fit_transform(y)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(379, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 20.5],\n",
       "       [  5.6],\n",
       "       [ 13.4],\n",
       "       [ 12.6],\n",
       "       [ 21.2],\n",
       "       [ 19.7],\n",
       "       [ 32.4],\n",
       "       [ 14.8],\n",
       "       [ 33. ],\n",
       "       [ 21.4],\n",
       "       [ 30.1],\n",
       "       [ 36. ],\n",
       "       [  8.4],\n",
       "       [ 21.6],\n",
       "       [ 16.3],\n",
       "       [ 23. ],\n",
       "       [ 14.9],\n",
       "       [ 14.1],\n",
       "       [ 31.1],\n",
       "       [ 11.9],\n",
       "       [ 12.7],\n",
       "       [ 27.9],\n",
       "       [ 20.8],\n",
       "       [ 19.6],\n",
       "       [ 32. ],\n",
       "       [ 21.9],\n",
       "       [ 23.2],\n",
       "       [ 23.8],\n",
       "       [ 10.8],\n",
       "       [ 34.9],\n",
       "       [ 19.1],\n",
       "       [ 26.5],\n",
       "       [ 10.5],\n",
       "       [ 17.5],\n",
       "       [ 24. ],\n",
       "       [ 36.1],\n",
       "       [ 25.3],\n",
       "       [ 13.8],\n",
       "       [ 27.5],\n",
       "       [ 24.6],\n",
       "       [ 12.7],\n",
       "       [  9.5],\n",
       "       [ 32.7],\n",
       "       [ 13.8],\n",
       "       [ 23.5],\n",
       "       [ 17.7],\n",
       "       [ 15.6],\n",
       "       [ 22.5],\n",
       "       [ 26.2],\n",
       "       [ 20.6],\n",
       "       [ 14.1],\n",
       "       [ 33.3],\n",
       "       [ 15.2],\n",
       "       [ 14.9],\n",
       "       [ 21.6],\n",
       "       [ 17.2],\n",
       "       [ 23.1],\n",
       "       [ 11.7],\n",
       "       [ 20.6],\n",
       "       [ 22.2],\n",
       "       [ 23.1],\n",
       "       [ 18.4],\n",
       "       [ 43.8],\n",
       "       [ 21.1],\n",
       "       [ 14.9],\n",
       "       [ 28.7],\n",
       "       [ 23.3],\n",
       "       [ 13.8],\n",
       "       [ 19.7],\n",
       "       [ 30.5],\n",
       "       [ 19. ],\n",
       "       [ 19.1],\n",
       "       [ 19. ],\n",
       "       [ 26.6],\n",
       "       [ 17.5],\n",
       "       [ 21.9],\n",
       "       [ 13.8],\n",
       "       [  8.8],\n",
       "       [ 19.4],\n",
       "       [ 28.1],\n",
       "       [ 21. ],\n",
       "       [ 11.8],\n",
       "       [  7.2],\n",
       "       [ 24.1],\n",
       "       [ 20. ],\n",
       "       [ 18.9],\n",
       "       [ 50. ],\n",
       "       [ 13.3],\n",
       "       [ 50. ],\n",
       "       [ 41.3],\n",
       "       [ 28.7],\n",
       "       [ 19.9],\n",
       "       [ 16.5],\n",
       "       [ 10.9],\n",
       "       [ 13.4],\n",
       "       [ 32.9],\n",
       "       [ 20.6],\n",
       "       [ 25. ],\n",
       "       [ 19.5],\n",
       "       [ 19.9],\n",
       "       [ 15.4],\n",
       "       [ 21.7],\n",
       "       [ 31.5],\n",
       "       [ 27.1],\n",
       "       [  8.3],\n",
       "       [ 13.6],\n",
       "       [  8.8],\n",
       "       [ 22.5],\n",
       "       [  7.5],\n",
       "       [ 28.6],\n",
       "       [ 50. ],\n",
       "       [ 11.5],\n",
       "       [ 13.5],\n",
       "       [ 24.4],\n",
       "       [ 36.2],\n",
       "       [ 21.4],\n",
       "       [ 18.5],\n",
       "       [ 22.6],\n",
       "       [ 24.8],\n",
       "       [ 19.3],\n",
       "       [ 29.8],\n",
       "       [ 16.4],\n",
       "       [  8.4],\n",
       "       [ 24.7],\n",
       "       [ 20.1],\n",
       "       [ 13.1],\n",
       "       [ 35.2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "y_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从sklearn.\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#初始化k近邻回归器，并且调整配置，使得预测方式为平均回归   weights='uniform'\n",
    "uni_knr = KNeighborsRegressor(weights='uniform')\n",
    "uni_knr.fit(X_train,y_train)\n",
    "uni_knr_y_predict=uni_knr.predict(X_test)\n",
    "\n",
    "#初始化k近邻回归器，并且调整配置，使得预测的方式根据距离加权回归\n",
    "dis_knr=KNeighborsRegressor(weights='distance')\n",
    "dis_knr.fit(X_train,y_train)\n",
    "dis_knr_y_predict=dis_knr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights取值为uniform时的评分:\n",
      "R-squared 评分 0.693676533978\n",
      "0.693676533978\n",
      "The mean squared error 评分: 23.7527181102\n",
      "The mean abs error 评分： 2.90708661417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "print('weights取值为uniform时的评分:')\n",
    "#使用  R-squared   MSE  MAE  三种指标对平均回归配置的K近邻模型在测试集上进行性能评估\n",
    "print('R-squared 评分',uni_knr.score(X_test,y_test))\n",
    "print(r2_score(y_test,uni_knr_y_predict))    #顺序不能变\n",
    "\n",
    "#y_scaler.inverse_transform(y_test)     还原标准结果\n",
    "#y_scaler.inverse_transform(uni_knr_y_predict)  还原预测结果\n",
    "#下面的只有打分\n",
    "print('The mean squared error 评分:',\n",
    "     mean_squared_error(y_scaler.inverse_transform(uni_knr_y_predict) ,y_scaler.inverse_transform(y_test)) )\n",
    "\n",
    "print('The mean abs error 评分：',\n",
    "     mean_absolute_error(y_scaler.inverse_transform(y_test),y_scaler.inverse_transform(uni_knr_y_predict) )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights 取值为  distance  时评分\n",
      "R-squared  value: 0.722319360622\n",
      "0.693676533978\n",
      "MSE 评分： 23.7527181102\n",
      "MAE 评分： 2.90708661417\n"
     ]
    }
   ],
   "source": [
    "#使用 R-squared   MSE MAE  三种指标对根据距离加权回归配置的K近邻模型在测试上集上进行性能评估\n",
    "print('weights 取值为  distance  时评分')\n",
    "print('R-squared  value:',\n",
    "     dis_knr.score(X_test,y_test))\n",
    "print(r2_score(y_test,uni_knr_y_predict))\n",
    "\n",
    "print('MSE 评分：',\n",
    "     mean_squared_error(y_scaler.inverse_transform(uni_knr_y_predict) ,y_scaler.inverse_transform(y_test)))\n",
    "print('MAE 评分：',\n",
    "     mean_absolute_error(y_scaler.inverse_transform(y_test),y_scaler.inverse_transform(uni_knr_y_predict) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自定义的平均绝对值误差: [ 2.90708661]\n",
      "自定义的均方误差： [ 23.75271811]\n"
     ]
    }
   ],
   "source": [
    "#自定义实现三个指标：\n",
    "#  1 .mean_absolute_error:平均绝对误差   MAE=sum(x-y)/n\n",
    "def myMae(ytest,ypredict):\n",
    "    errab=[]\n",
    "    n=len(ypredict)\n",
    "    for i in range(n):\n",
    "        errab.append(abs(ytest[i]-ypredict[i]))\n",
    "    mae=sum(errab)/n\n",
    "    return mae\n",
    "print('自定义的平均绝对值误差:',myMae(y_scaler.inverse_transform(y_test) ,y_scaler.inverse_transform(uni_knr_y_predict)))\n",
    "\n",
    "\n",
    "#  2.mean_squared_error : 均方误差    MSE=sum( (x-y)^2 )/n\n",
    "def myMse(ytest,ypredict):\n",
    "    err=[]\n",
    "    n=len(ypredict)\n",
    "    for i in range(n):\n",
    "        err.append(ytest[i]-ypredict[i])\n",
    "    mse=sum(np.power(err,2))/n\n",
    "    return mse\n",
    "print('自定义的均方误差：',myMse(y_scaler.inverse_transform(uni_knr_y_predict) ,y_scaler.inverse_transform(y_test) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myR2_score： 0.722319360622\n",
      "R2： 0.722319360622\n"
     ]
    }
   ],
   "source": [
    "#3.拟合度指标\n",
    "def myR2_score(ytest,ypredict):\n",
    "    ss_res=np.sum(np.square(ytest-ypredict))\n",
    "    mean=np.mean(ytest,axis=0)\n",
    "    ss_ree=np.sum(np.square(ytest-mean))\n",
    "    return (1-(ss_res/ss_ree))\n",
    "\n",
    "def R2(ytest,ypredict):\n",
    "    return 1-((ytest-ypredict)**2).sum()/((ytest-ytest.mean())**2).sum()\n",
    "\n",
    "print('myR2_score：',myR2_score(y_test,dis_knr_y_predict.reshape(-1,1) ) )\n",
    "print('R2：',R2(y_test,dis_knr_y_predict.reshape(-1,1) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳效果:0.800\n",
      "最优参数组合:\n",
      "\tn_neighbors:2\n",
      "\tp:1\n",
      "\tweights:'distance'\n"
     ]
    }
   ],
   "source": [
    "#sklearn.datasets 里面调入波士顿房价的数据\n",
    "boston=load_boston()\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "\n",
    "\n",
    "X_scaler=StandardScaler()\n",
    "X=X_scaler.fit_transform(X)\n",
    "\n",
    "y=np.array(y).reshape(-1,1)  #  -1将列变为行 加列  m行1列  \n",
    "y_scaler=StandardScaler()\n",
    "y=y_scaler.fit_transform(y)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=33)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#超参数搜索\n",
    "ps=[1,2,10]\n",
    "ks=[i for i in range(1,30)]\n",
    "ws=['uniform','distance']  #指定权重算法\n",
    "par_grid={'p':ps,'n_neighbors':ks,'weights':ws}\n",
    "clf=GridSearchCV(KNeighborsRegressor(),par_grid,cv=5)  #cv表示5折交叉\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print('最佳效果:%0.3f'%clf.best_score_)\n",
    "print('最优参数组合:')\n",
    "best_parameters=clf.best_estimator_.get_params()\n",
    "for par_name in sorted(par_grid.keys()):\n",
    "    print('\\t%s:%r'%(par_name,best_parameters[par_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=KNeighborsRegressor(p=2,weights='distance',n_neighbors=7)\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.92350482487\n",
      "MSE: 23.6182366702\n",
      "R-squared: 0.695410854262\n",
      "R2： 0.695410854262\n"
     ]
    }
   ],
   "source": [
    "#评估模型\n",
    "y_test_orgin=y_scaler.inverse_transform(y_test)\n",
    "y_predict_orgin=y_scaler.inverse_transform(y_predict)\n",
    "print('MAE:',mean_absolute_error(y_test_orgin,y_predict_orgin))\n",
    "print('MSE:',mean_squared_error(y_test_orgin,y_predict_orgin))\n",
    "print('R-squared:',clf.score(X_test,y_test))\n",
    "print('R2：',r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.644972322\n",
      "MSE: 21.4124847473\n",
      "R-squared: 0.723857012344\n",
      "R2： 0.723857012344\n"
     ]
    }
   ],
   "source": [
    "clf=KNeighborsRegressor(p=1,weights='distance',n_neighbors=7)\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict=clf.predict(X_test)\n",
    "#评估模型\n",
    "y_test_orgin=y_scaler.inverse_transform(y_test)\n",
    "y_predict_orgin=y_scaler.inverse_transform(y_predict)\n",
    "print('MAE:',mean_absolute_error(y_test_orgin,y_predict_orgin))\n",
    "print('MSE:',mean_squared_error(y_test_orgin,y_predict_orgin))\n",
    "print('R-squared:',clf.score(X_test,y_test))\n",
    "print('R2：',r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.6\n"
     ]
    }
   ],
   "source": [
    "boston=load_boston()\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "\n",
    "X.shape\n",
    "\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston=load_boston()\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "#print(X)\n",
    "pca=PCA(n_components=5)\n",
    "x_pca=pca.fit_transform(X)\n",
    "\n",
    "#切分数据\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_pca,y_pca,test_size=0.25,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳效果:0.423\n",
      "最优参数组合:\n",
      "\tn_neighbors:5\n",
      "\tp:10\n",
      "\tweights:'distance'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#超参数搜索\n",
    "ps=[1,2,10]\n",
    "ks=[i for i in range(1,30)]\n",
    "ws=['uniform','distance']  #指定权重算法\n",
    "par_grid={'p':ps,'n_neighbors':ks,'weights':ws}\n",
    "clf=GridSearchCV(KNeighborsRegressor(),par_grid,cv=5)  #cv表示5折交叉\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print('最佳效果:%0.3f'%clf.best_score_)\n",
    "print('最优参数组合:')\n",
    "best_parameters=clf.best_estimator_.get_params()\n",
    "for par_name in sorted(par_grid.keys()):\n",
    "    print('\\t%s:%r'%(par_name,best_parameters[par_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 38.2996294293\n",
      "MSE: 3153.62417432\n",
      "R-squared: 0.518236576625\n",
      "R2： 0.518236576625\n"
     ]
    }
   ],
   "source": [
    "clf=KNeighborsRegressor(p=10,weights='distance',n_neighbors=5)\n",
    "clf.fit(x_train,y_train)\n",
    "y_predict=clf.predict(x_test)\n",
    "\n",
    "#评估模型\n",
    "y_test_orgin=y_scaler.inverse_transform(y_test)\n",
    "y_predict_orgin=y_scaler.inverse_transform(y_predict)\n",
    "print('MAE:',mean_absolute_error(y_test_orgin,y_predict_orgin))\n",
    "print('MSE:',mean_squared_error(y_test_orgin,y_predict_orgin))\n",
    "print('R-squared:',clf.score(x_test,y_test))\n",
    "print('R2：',r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr  #计算皮尔逊相关系数\n",
    "boston=load_boston()\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "\n",
    "pearsonr.\n",
    "\n",
    "#切分数据\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_pca,y_pca,test_size=0.25,random_state=33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
